# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Reconcile multi-batch matrices by batch-balancing KNN
#'
#' @param data_nk_vec a list of sample x factor matrices
#' @param row_names_vec a list of sample x 1 names
#' @param KNN_PER_BATCH (default: 3)
#' @param BLOCK_SIZE each parallel job size (default: 100)
#' @param NUM_THREADS number of parallel threads (default: 1)
#' @param IP_DISTANCE inner product distance (default: FALSE)
#' @param verbose (default: TRUE)
#'
#' @return a list that contains:
#' \itemize{
#'  \item adjusted (N x K) matrix
#'  \item bbknn batch-balanced kNN adjacency matrix
#'  \item batches batch membership
#'  \item knn edges
#' }
#'
asap_bbknn <- function(data_nk_vec, row_names_vec, KNN_PER_BATCH = 3L, BLOCK_SIZE = 100L, NUM_THREADS = 1L, IP_DISTANCE = FALSE, verbose = TRUE) {
    .Call('_asapR_asap_bbknn', PACKAGE = 'asapR', data_nk_vec, row_names_vec, KNN_PER_BATCH, BLOCK_SIZE, NUM_THREADS, IP_DISTANCE, verbose)
}

#' Generate approximate pseudo-bulk interaction data by random projections
#'
#' @param mtx_file matrix-market-formatted data file (bgzip)
#' @param row_file row names (gene/feature names)
#' @param col_file column names (cell/column names)
#' @param idx_file matrix-market colum index file
#' @param num_factors a desired number of random factors
#' @param W_nn_list list(src.index, tgt.index, [weights]) for columns
#'
#' @param A_dd_list list(src.index, tgt.index, [weights]) for features
#'
#' @param rseed random seed
#' @param do_product yi * yj for interaction (default: FALSE)
#' @param do_log1p log(x + 1) transformation (default: FALSE)
#' @param do_down_sample down-sampling (default: FALSE)
#' @param save_rand_proj save random projection (default: FALSE)
#' @param weighted_rand_proj save random projection (default: FALSE)
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param EDGE_PER_SAMPLE down-sampling cell per sample (default: 100)
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param MAX_ROW_WORD maximum words per line in `row_file`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_file`
#' @param COL_WORD_SEP word separation character to replace white space
#' @param verbose verbosity
#'
#' @return a list
#' \itemize{
#' \item `PB` pseudobulk (average) data (feature x sample)
#' \item `sum` pseudobulk (sum) data (feature x sample)
#' \item `size` size per sample (sample x 1)
#' \item `positions` pseudobulk sample positions (cell pair x 1)
#' \item `rand.dict` random dictionary (proj factor x feature)
#' \item `rand.proj` random projection results (sample x proj factor)
#' \item `colnames` column (cell) names
#' \item `rownames` feature (gene) names
#' }
#'
#'
asap_interaction_random_bulk <- function(mtx_file, row_file, col_file, idx_file, num_factors, W_nn_list, A_dd_list = NULL, rseed = 42L, do_product = FALSE, do_log1p = FALSE, do_down_sample = FALSE, save_rand_proj = FALSE, weighted_rand_proj = FALSE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, EDGE_PER_SAMPLE = 100L, a0 = 1e-8, b0 = 1, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@', verbose = FALSE) {
    .Call('_asapR_asap_interaction_random_bulk', PACKAGE = 'asapR', mtx_file, row_file, col_file, idx_file, num_factors, W_nn_list, A_dd_list, rseed, do_product, do_log1p, do_down_sample, save_rand_proj, weighted_rand_proj, NUM_THREADS, BLOCK_SIZE, EDGE_PER_SAMPLE, a0, b0, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP, verbose)
}

#' Topic statistics to estimate factor loading
#'
#' @param mtx_file matrix-market-formatted data file (D x N, bgzip)
#' @param row_file row names file (D x 1)
#' @param col_file column names file (N x 1)
#' @param idx_file matrix-market colum index file
#' @param log_x D x K log dictionary/design matrix
#' @param x_row_names row names log_x (D vector)
#' @param W_nn_list list(src.index, tgt.index, [weights]) for columns
#'
#' @param A_dd_list list(src.index, tgt.index, [weights]) for features
#' @param do_product yi * yj for interaction (default: FALSE)
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param MAX_ROW_WORD maximum words per line in `row_files[i]`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_files[i]`
#' @param COL_WORD_SEP word separation character to replace white space
#' @param verbose verbosity
#'
#' @return a list that contains:
#' \itemize{
#'  \item beta dictionary matrix (row x factor)
#'  \item corr empirical correlation (column x factor)
#'  \item colsum the sum of each column (column x 1)
#' }
#'
asap_interaction_topic_stat <- function(mtx_file, row_file, col_file, idx_file, log_x, x_row_names, W_nn_list, A_dd_list = NULL, do_product = FALSE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@', verbose = FALSE) {
    .Call('_asapR_asap_interaction_topic_stat', PACKAGE = 'asapR', mtx_file, row_file, col_file, idx_file, log_x, x_row_names, W_nn_list, A_dd_list, do_product, NUM_THREADS, BLOCK_SIZE, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP, verbose)
}

#' A quick NMF estimation based on alternating Poisson regressions
#'
#' @param Y_ non-negative data matrix (gene x sample)
#' @param maxK maximum number of factors
#' @param max_iter max number of optimization steps
#' @param min_iter min number of optimization steps
#' @param burnin number of initiation steps (default: 50)
#' @param verbose verbosity
#' @param a0 gamma(a0, b0) default: a0 = 1e-8
#' @param b0 gamma(a0, b0) default: b0 = 1
#' @param do_scale scale each column by standard deviation (default: TRUE)
#' @param do_log1p do log(1+y) transformation
#' @param rseed random seed (default: 1337)
#' @param svd_init initialize by SVD (default: FALSE)
#' @param EPS (default: 1e-8)
#'
#' @return a list that contains:
#'  \itemize{
#'   \item `log.likelihood` Log-likelihood trace
#'   \item `std_log_x` Standardized log-dictionary (gene x factor)
#'   \item `corr` Empirical correlation (sample x factor)
#'   \item `model` A list: beta (gene x factor) and theta (sample x factor)
#' }
#'
#'
asap_fit_nmf <- function(Y_, maxK, max_iter = 100L, r_A_dd_list = NULL, r_A_nn_list = NULL, burnin = 0L, verbose = TRUE, a0 = 1e-8, b0 = 1, do_log1p = FALSE, rseed = 1337L, svd_init = FALSE, EPS = 1e-8, NUM_THREADS = 1L) {
    .Call('_asapR_asap_fit_nmf', PACKAGE = 'asapR', Y_, maxK, max_iter, r_A_dd_list, r_A_nn_list, burnin, verbose, a0, b0, do_log1p, rseed, svd_init, EPS, NUM_THREADS)
}

#' A quick NMF estimation based on alternating Poisson regressions
#' while sharing a dictionary/factors matrix
#'
#' @param y_dn_vec a list of non-negative data matrices (gene x sample)
#' @param maxK maximum number of factors
#' @param max_iter max number of optimization steps
#' @param min_iter min number of optimization steps
#' @param burnin number of initiation steps (default: 50)
#' @param verbose verbosity
#' @param a0 gamma(a0, b0) default: a0 = 1
#' @param b0 gamma(a0, b0) default: b0 = 1
#' @param do_scale scale each column by standard deviation (default: TRUE)
#' @param do_log1p do log(1+y) transformation
#' @param rseed random seed (default: 1337)
#' @param svd_init initialize by SVD (default: FALSE)
#' @param EPS (default: 1e-8)
#'
#' @return a list that contains:
#'  \itemize{
#'   \item log.likelihood log-likelihood trace
#'   \item beta dictionary (gene x factor)
#'   \item log.beta log-dictionary (gene x factor)
#'   \item log.beta.sd sd(log-dictionary) (gene x factor)
#'   \item theta a list of loading matrices (sample x factor)
#'   \item log.theta a list of log loadings (sample x factor)
#'   \item log.theta.sd a list of standard deviations (sample x factor)
#' }
#'
#'
asap_fit_nmf_cbind <- function(y_dn_vec, maxK, max_iter = 100L, burnin = 0L, verbose = TRUE, a0 = 1, b0 = 1, do_log1p = FALSE, rseed = 1337L, svd_init = FALSE, EPS = 1e-8, NUM_THREADS = 1L) {
    .Call('_asapR_asap_fit_nmf_cbind', PACKAGE = 'asapR', y_dn_vec, maxK, max_iter, burnin, verbose, a0, b0, do_log1p, rseed, svd_init, EPS, NUM_THREADS)
}

#' A quick NMF estimation based on alternating Poisson regressions
#' while sharing a factor loading/topic proportion matrix
#'
#' @param y_dn_vec a list of non-negative data matrices (gene x sample)
#' @param maxK maximum number of factors
#' @param max_iter max number of optimization steps
#' @param min_iter min number of optimization steps
#' @param burnin number of initiation steps (default: 50)
#' @param verbose verbosity
#' @param a0 gamma(a0, b0) default: a0 = 1
#' @param b0 gamma(a0, b0) default: b0 = 1
#' @param do_scale scale each column by standard deviation (default: TRUE)
#' @param do_log1p do log(1+y) transformation
#' @param rseed random seed (default: 1337)
#' @param svd_init initialize by SVD (default: FALSE)
#' @param EPS (default: 1e-8)
#'
#' @return a list that contains:
#'  \itemize{
#'   \item log.likelihood log-likelihood trace
#'   \item theta dictionary (sample x factor)
#'   \item log.theta log-dictionary (sample x factor)
#'   \item log.theta.sd sd(log-dictionary) (sample x factor)
#'   \item beta a list of loading matrices (gene x factor)
#'   \item log.beta a list of log loadings (gene x factor)
#'   \item log.beta.sd a list of standard deviations (gene x factor)
#' }
#'
#'
asap_fit_nmf_rbind <- function(y_dn_vec, maxK, max_iter = 100L, burnin = 0L, verbose = TRUE, a0 = 1, b0 = 1, do_log1p = FALSE, rseed = 1337L, svd_init = FALSE, EPS = 1e-8, NUM_THREADS = 1L) {
    .Call('_asapR_asap_fit_nmf_rbind', PACKAGE = 'asapR', y_dn_vec, maxK, max_iter, burnin, verbose, a0, b0, do_log1p, rseed, svd_init, EPS, NUM_THREADS)
}

#' Generate approximate pseudo-bulk data by random projections
#'
#' @param mtx_file matrix-market-formatted data file (bgzip)
#' @param row_file row names (gene/feature names)
#' @param col_file column names (cell/column names)
#' @param idx_file matrix-market colum index file
#' @param num_factors a desired number of random factors
#' @param r_covar_n N x r covariates (default: NULL)
#' @param r_covar_d D x r covariates (default: NULL)
#' @param rseed random seed
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param do_log1p log(x + 1) transformation (default: FALSE)
#' @param do_down_sample down-sampling (default: FALSE)
#' @param save_rand_proj save random projection (default: FALSE)
#' @param weighted_rand_proj save random projection (default: FALSE)
#' @param CELL_PER_SAMPLE down-sampling cell per sample (default: 100)
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param MAX_ROW_WORD maximum words per line in `row_file`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_file`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @return a list
#' \itemize{
#' \item `PB` pseudobulk (average) data (feature x sample)
#' \item `sum` pseudobulk (sum) data (feature x sample)
#' \item `size` size per sample (sample x 1)
#' \item `positions` pseudobulk sample positions (cell x 1)
#' \item `rand.dict` random dictionary (proj factor x feature)
#' \item `rand.proj` random projection results (sample x proj factor)
#' \item `colnames` column (cell) names
#' \item `rownames` feature (gene) names
#' }
#'
asap_random_bulk <- function(mtx_file, row_file, col_file, idx_file, num_factors, r_covar_n = NULL, r_covar_d = NULL, rseed = 42L, verbose = FALSE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, do_log1p = FALSE, do_down_sample = FALSE, save_rand_proj = FALSE, weighted_rand_proj = FALSE, CELL_PER_SAMPLE = 100L, a0 = 1e-8, b0 = 1, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_asap_random_bulk', PACKAGE = 'asapR', mtx_file, row_file, col_file, idx_file, num_factors, r_covar_n, r_covar_d, rseed, verbose, NUM_THREADS, BLOCK_SIZE, do_log1p, do_down_sample, save_rand_proj, weighted_rand_proj, CELL_PER_SAMPLE, a0, b0, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP)
}

#' Generate approximate pseudo-bulk data by random projections
#' while sharing rows/features across multiple data sets.
#' Horizontal concatenation.
#'
#' @param mtx_files matrix-market-formatted data files (bgzip)
#' @param row_files row names (gene/feature names)
#' @param col_files column names (cell/column names)
#' @param idx_files matrix-market colum index files
#' @param num_factors a desired number of random factors
#' @param take_union_rows take union of rows (default: FALSE)
#' @param rseed random seed
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param do_batch_adj (default: FALSE)
#' @param do_log1p log(x + 1) transformation (default: FALSE)
#' @param do_down_sample down-sampling (default: TRUE)
#' @param save_rand_proj save random projection (default: FALSE)
#' @param KNN_CELL k-NN cells per batch between different batches (default: 3)
#' @param CELL_PER_SAMPLE down-sampling cell per sample (default: 100)
#' @param BATCH_ADJ_ITER batch Adjustment steps (default: 100)
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param MAX_ROW_WORD maximum words per line in `row_files[i]`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_files[i]`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @return a list
#' \itemize{
#' \item `PB` pseudobulk (average) data (feature x sample)
#' \item `sum` pseudobulk (sum) data (feature x sample)
#' \item `matched.sum` kNN-matched pseudobulk data (feature x sample)
#' \item `sum_db` batch-specific sum (feature x batch)
#' \item `size` size per sample (sample x 1)
#' \item `prob_bs` batch-specific frequency (batch x sample)
#' \item `size_bs` batch-specific size (batch x sample)
#' \item `batch.effect` batch effect (feature x batch)
#' \item `log.batch.effect` log batch effect (feature x batch)
#' \item `batch.names` batch names (batch x 1)
#' \item `positions` pseudobulk sample positions (cell x 1)
#' \item `rand.dict` random dictionary (proj factor x feature)
#' \item `rand.proj` random projection results (sample x proj factor)
#' \item `colnames` column (cell) names
#' \item `rownames` feature (gene) names
#' }
#'
asap_random_bulk_cbind <- function(mtx_files, row_files, col_files, idx_files, num_factors, take_union_rows = FALSE, rseed = 42L, verbose = TRUE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, do_batch_adj = TRUE, do_log1p = FALSE, do_down_sample = TRUE, save_rand_proj = FALSE, KNN_CELL = 3L, CELL_PER_SAMPLE = 100L, BATCH_ADJ_ITER = 100L, a0 = 1e-8, b0 = 1, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_asap_random_bulk_cbind', PACKAGE = 'asapR', mtx_files, row_files, col_files, idx_files, num_factors, take_union_rows, rseed, verbose, NUM_THREADS, BLOCK_SIZE, do_batch_adj, do_log1p, do_down_sample, save_rand_proj, KNN_CELL, CELL_PER_SAMPLE, BATCH_ADJ_ITER, a0, b0, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP)
}

#' Generate approximate pseudo-bulk data by random projections
#' while sharing columns/cells across multiple data sets.
#' Vertical concatenation.
#'
#' @param mtx_files matrix-market-formatted data files (bgzip)
#' @param row_files row names (gene/feature names)
#' @param col_files column names (cell/column names)
#' @param idx_files matrix-market colum index files
#' @param num_factors a desired number of random factors per data set
#'
#' @param rseed random seed
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param do_log1p log(x + 1) transformation (default: FALSE)
#' @param do_down_sample down-sampling (default: FALSE)
#' @param save_rand_proj save random projection (default: FALSE)
#' @param weighted_rand_proj save random projection (default: FALSE)
#' @param CELL_PER_SAMPLE down-sampling cell per sample (default: 100)
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param MAX_ROW_WORD maximum words per line in `row_files[i]`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_files[i]`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @return a list
#' \itemize{
#' \item `PB.list` pseudobulk (average) data (feature x sample) for each type
#' \item `sum.list` pseudobulk (sum) data (feature x sample) for each type
#' \item `size.list` size per sample (sample x 1) for each type
#' \item `rownames.list` feature (gene) names for each type
#' \item `colnames` column (cell) names across data types
#' \item `positions` pseudobulk sample positions (cell x 1)
#' \item `rand.proj` random projection results (sample x proj factor)
#' \item `colnames` column (cell) names
#' }
#'
asap_random_bulk_rbind <- function(mtx_files, row_files, col_files, idx_files, num_factors, rseed = 42L, verbose = TRUE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, do_log1p = FALSE, do_down_sample = FALSE, save_rand_proj = FALSE, weighted_rand_proj = FALSE, CELL_PER_SAMPLE = 100L, a0 = 1e-8, b0 = 1, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_asap_random_bulk_rbind', PACKAGE = 'asapR', mtx_files, row_files, col_files, idx_files, num_factors, rseed, verbose, NUM_THREADS, BLOCK_SIZE, do_log1p, do_down_sample, save_rand_proj, weighted_rand_proj, CELL_PER_SAMPLE, a0, b0, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP)
}

#' Calibrate topic proportions based on sufficient statistics
#'
#' @param X_dk dictionary matrix (feature D  x factor K)
#' @param R_nk correlation matrix (sample N x factor K)
#' @param Y_n sum vector (sample N x 1)
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param max_iter maximum iterations (default: 10)
#' @param NUM_THREADS number of parallel threads (default: 1)
#' @param stdize_r standardize correlation matrix R (default: TRUE)
#' @param verbose (default: TRUE)
#'
#' @return a list that contains:
#' \itemize{
#'  \item beta (D x K) matrix
#'  \item theta (N x K) matrix
#'  \item log.theta (N x K) log matrix
#'  \item log.theta.sd (N x K) standard deviation matrix
#' }
#'
asap_topic_pmf <- function(X_dk, R_nk, Y_n, a0 = 1e-8, b0 = 1.0, max_iter = 10L, NUM_THREADS = 1L, stdize_r = TRUE, verbose = TRUE) {
    .Call('_asapR_asap_topic_pmf', PACKAGE = 'asapR', X_dk, R_nk, Y_n, a0, b0, max_iter, NUM_THREADS, stdize_r, verbose)
}

#' Topic statistics to estimate factor loading
#'
#' @param mtx_file matrix-market-formatted data file (D x N, bgzip)
#' @param row_file row names file (D x 1)
#' @param col_file column names file (N x 1)
#' @param idx_file matrix-market colum index file
#' @param log_x D x K log dictionary/design matrix
#' @param x_row_names row names log_x (D vector)
#' @param do_log1p do log(1+y) transformation
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param MAX_ROW_WORD maximum words per line in `row_files[i]`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_files[i]`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @return a list that contains:
#' \itemize{
#'  \item beta dictionary matrix (row x factor)
#'  \item corr empirical correlation (column x factor)
#'  \item colsum the sum of each column (column x 1)
#' }
#'
asap_topic_stat <- function(mtx_file, row_file, col_file, idx_file, log_x, x_row_names, do_log1p = FALSE, verbose = FALSE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_asap_topic_stat', PACKAGE = 'asapR', mtx_file, row_file, col_file, idx_file, log_x, x_row_names, do_log1p, verbose, NUM_THREADS, BLOCK_SIZE, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP)
}

#' Poisson regression to estimate factor loading
#'
#' @param Y D x N data matrix
#' @param log_x D x K log dictionary/design matrix
#' @param a0 gamma(a0, b0) (default: 1e-8)
#' @param b0 gamma(a0, b0) (default: 1)
#' @param do_log1p do log(1+y) transformation (default: FALSE)
#' @param verbose verbosity (default: false)
#'
#' @return a list that contains:
#' \itemize{
#'  \item beta (D x K) matrix
#'  \item theta (N x K) matrix
#'  \item log.theta (N x K) log matrix
#'  \item log.theta.sd (N x K) standard deviation matrix
#'  \item corr (N x K) topic correlation matrix
#'  \item colsum (N x 1) column sum vector
#' }
#'
asap_regression <- function(Y_, log_x, a0 = 1e-8, b0 = 1.0, max_iter = 10L, do_log1p = FALSE, verbose = TRUE) {
    .Call('_asapR_asap_regression', PACKAGE = 'asapR', Y_, log_x, a0, b0, max_iter, do_log1p, verbose)
}

#' Topic statistics to estimate factor loading
#'
#' @param mtx_file matrix-market-formatted data file (D x N, bgzip)
#' @param row_file row names file (D x 1)
#' @param col_file column names file (N x 1)
#' @param idx_file matrix-market colum index file
#' @param log_x D x K log dictionary/design matrix
#' @param x_row_names row names log_x (D vector)
#' @param do_log1p do log(1+y) transformation
#' @param verbose verbosity
#' @param NUM_THREADS number of threads in data reading
#' @param BLOCK_SIZE disk I/O block size (number of columns)
#' @param MAX_ROW_WORD maximum words per line in `row_files[i]`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @param MAX_COL_WORD maximum words per line in `col_files[i]`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @return a list that contains:
#' \itemize{
#'  \item beta dictionary matrix (row x factor)
#'  \item corr empirical correlation (column x factor)
#'  \item colsum the sum of each column (column x 1)
#' }
#'
asap_topic_stat_rbind <- function(mtx_files, row_files, col_files, idx_files, logX_vec, x_row_names_vec, do_log1p = FALSE, verbose = FALSE, NUM_THREADS = 1L, BLOCK_SIZE = 100L, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_', MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_asap_topic_stat_rbind', PACKAGE = 'asapR', mtx_files, row_files, col_files, idx_files, logX_vec, x_row_names_vec, do_log1p, verbose, NUM_THREADS, BLOCK_SIZE, MAX_ROW_WORD, ROW_WORD_SEP, MAX_COL_WORD, COL_WORD_SEP)
}

#' Stretch non-negative matrix
#'
#' @param Y non-negative data matrix(gene x sample)
#' @param qq_min min quantile (default: 0.01)
#' @param qq_max min quantile (default: 0.99)
#' @param std_min min after standardization of log (default: -8)
#' @param std_max max after standardization of log (default: 8)
#' @param verbose speak more (default: TRUE)
#'
stretch_matrix_columns <- function(Y, qq_min = 0.01, qq_max = 0.99, std_min = -8, std_max = 8, verbose = TRUE) {
    .Call('_asapR_stretch_matrix_columns', PACKAGE = 'asapR', Y, qq_min, qq_max, std_min, std_max, verbose)
}

#' Clustering the rows of a count data matrix
#'
#' @param X data matrix
#' @param Ltrunc DPM truncation level
#' @param alpha DPM parameter
#' @param a0 prior ~ Gamma(a0, b0) (default: 1e-2)
#' @param b0 prior ~ Gamma(a0, b0) (default: 1e-4)
#' @param rseed random seed (default: 42)
#' @param mcmc number of MCMC iterations (default: 100)
#' @param burnin number iterations to discard (default: 10)
#' @param verbose verbosity
#'
fit_poisson_cluster_rows <- function(X, Ltrunc, alpha = 1, a0 = 1e-2, b0 = 1e-4, rseed = 42L, mcmc = 100L, burnin = 10L, verbose = TRUE) {
    .Call('_asapR_fit_poisson_cluster_rows', PACKAGE = 'asapR', X, Ltrunc, alpha, a0, b0, rseed, mcmc, burnin, verbose)
}

#' Collapse N x N adjacency network into S x S
#'
#' @param W_nn_list adjacency list
#' @param r_positions collapsing positions
#' @param N number of vertices
#' @param S number of meta-vertices
#' @param verbose verbosity
#'
#' @return a list of {rows, columns, weights}
#'
collapse_network <- function(W_nn_list, r_positions, N, S, verbose = TRUE) {
    .Call('_asapR_collapse_network', PACKAGE = 'asapR', W_nn_list, r_positions, N, S, verbose)
}

#' Assign best topic membership for the edges
#'
#' @param A_dd D x D adjacency matrix
#' @param beta_dt D x T node propensity matrix
#' @param cutoff A[i,j] cutoff (default: 1e-8)
#' @param verbose verbosity
#'
decompose_network <- function(A_dd, beta_dt, cutoff = 1e-8, verbose = TRUE) {
    .Call('_asapR_decompose_network', PACKAGE = 'asapR', A_dd, beta_dt, cutoff, verbose)
}

#' Take a subset of rows and create a new MTX file-set
#'
#' @description For the new mtx file, empty columns with only zero
#'   elements will be removed.
#'
#' @param mtx_file data file
#' @param row_file row file
#' @param col_file column file
#' @param selected selected row names
#' @param output output header
#' @param MAX_ROW_WORD maximum words per line in `row_file`
#' @param ROW_WORD_SEP word separation character to replace white space
#' @return a list of file names: {output}.{mtx,rows,cols}.gz
#'
#' @examples
#'
#' options(stringsAsFactors=FALSE)
#' rr <- rgamma(20, 1, 1)
#' mm <- matrix(rgamma(10 * 2, 1, 1), 10, 2)
#' src.hdr <- "test_org"
#' src.files <- mmutil_simulate_poisson(mm, rr, src.hdr)
#' Y <- Matrix::readMM(src.files$mtx)
#' rownames(Y) <- read.table(src.files$row)$V1
#' print(Y)
#' sub.rows <- sort(read.table(src.files$row)$V1[sample(10,3)])
#' print(sub.rows)
#' tgt.hdr <- "test_sub"
#' tgt.files <- mmutil_copy_selected_rows(
#'                src.files$mtx,
#'                src.files$row,
#'                src.files$col,
#'                sub.rows,
#'                tgt.hdr)
#' Y <- Matrix::readMM(tgt.files$mtx)
#' colnames(Y) <- read.table(tgt.files$col)$V1
#' rownames(Y) <- read.table(tgt.files$row)$V1
#' print(Y)
#' unlink(list.files(pattern = src.hdr))
#' unlink(list.files(pattern = tgt.hdr))
#'
mmutil_copy_selected_rows <- function(mtx_file, row_file, col_file, r_selected, output, MAX_ROW_WORD = 2L, ROW_WORD_SEP = '_') {
    .Call('_asapR_mmutil_copy_selected_rows', PACKAGE = 'asapR', mtx_file, row_file, col_file, r_selected, output, MAX_ROW_WORD, ROW_WORD_SEP)
}

#' Take a subset of columns and create a new MTX file-set
#'
#' @param mtx_file data file
#' @param row_file row file
#' @param col_file column file
#' @param selected selected column names
#' @param output output header
#' @param MAX_COL_WORD maximum words per line in `col_file`
#' @param COL_WORD_SEP word separation character to replace white space
#'
#' @examples
#'
#' options(stringsAsFactors=FALSE)
#' rr <- rgamma(20, 1, 1)
#' mm <- matrix(rgamma(10 * 2, 1, 1), 10, 2)
#' src.hdr <- "test_org"
#' src.files <- mmutil_simulate_poisson(mm, rr, src.hdr)
#' Y <- Matrix::readMM(src.files$mtx)
#' colnames(Y) <- read.table(src.files$col)$V1
#' print(Y)
#' sub.cols <- sort(read.table(src.files$col)$V1[sample(20,3)])
#' print(sub.cols)
#' tgt.hdr <- "test_sub"
#' tgt.files <- mmutil_copy_selected_columns(
#'                          src.files$mtx,
#'                          src.files$row,
#'                          src.files$col,
#'                          sub.cols, tgt.hdr)
#' Y <- Matrix::readMM(tgt.files$mtx)
#' colnames(Y) <- read.table(tgt.files$col)$V1
#' print(Y)
#' unlink(list.files(pattern = src.hdr))
#' unlink(list.files(pattern = tgt.hdr))
#'
mmutil_copy_selected_columns <- function(mtx_file, row_file, col_file, r_selected, output, MAX_COL_WORD = 100L, COL_WORD_SEP = '@') {
    .Call('_asapR_mmutil_copy_selected_columns', PACKAGE = 'asapR', mtx_file, row_file, col_file, r_selected, output, MAX_COL_WORD, COL_WORD_SEP)
}

#' Create an index file for a given MTX
#'
#' @param mtx_file data file
#' @param index_file index file
#'
#' @usage mmutil_build_index(mtx_file, index_file)
#'
#' @return EXIT_SUCCESS or EXIT_FAILURE
#'
mmutil_build_index <- function(mtx_file, index_file = "") {
    .Call('_asapR_mmutil_build_index', PACKAGE = 'asapR', mtx_file, index_file)
}

#' Read an index file to R
#'
#' @param index_file index file
#'
#' @return a vector column index (a vector of memory locations)
#'
mmutil_read_index <- function(index_file) {
    .Call('_asapR_mmutil_read_index', PACKAGE = 'asapR', index_file)
}

#' Check if the index tab is valid
#'
#' @param mtx_file data file
#' @param index_tab index tab (a vector of memory locations)
#'
#' @return TRUE or FALSE
#'
mmutil_check_index <- function(mtx_file, index_tab) {
    .Call('_asapR_mmutil_check_index', PACKAGE = 'asapR', mtx_file, index_tab)
}

#' Just read the header information
#'
#' @param mtx_file data file
#'
#' @return info
#'
mmutil_info <- function(mtx_file) {
    .Call('_asapR_mmutil_info', PACKAGE = 'asapR', mtx_file)
}

#' Write down sparse matrix to the disk
#' @param X sparse matrix
#' @param mtx_file file name
#'
#' @return EXIT_SUCCESS or EXIT_FAILURE
mmutil_write_mtx <- function(X, mtx_file) {
    .Call('_asapR_mmutil_write_mtx', PACKAGE = 'asapR', X, mtx_file)
}

#' Read a subset of columns from the data matrix
#' @param mtx_file data file
#' @param memory_location column -> memory location
#' @param r_column_index column indexes to retrieve (1-based)
#'
#' @return lists of rows, columns, values
#'
mmutil_read_columns_sparse <- function(mtx_file, memory_location, r_column_index, verbose = FALSE) {
    .Call('_asapR_mmutil_read_columns_sparse', PACKAGE = 'asapR', mtx_file, memory_location, r_column_index, verbose)
}

#' Read a subset of columns from the data matrix
#' @param mtx_file data file
#' @param memory_location column -> memory location
#' @param r_column_index column indexes to retrieve (1-based)
#'
#' @return a dense sub-matrix
#'
mmutil_read_columns <- function(mtx_file, memory_location, r_column_index, verbose = FALSE) {
    .Call('_asapR_mmutil_read_columns', PACKAGE = 'asapR', mtx_file, memory_location, r_column_index, verbose)
}

#' Read a subset of rows and columns from the data matrix
#' @param mtx_file data file
#' @param memory_location column -> memory location
#' @param r_row_index row indexes to retrieve (1-based)
#' @param r_column_index column indexes to retrieve (1-based)
#' @param verbose verbosity
#'
#' @return a dense sub-matrix
#'
mmutil_read_rows_columns <- function(mtx_file, memory_location, r_row_index, r_column_index, verbose = FALSE) {
    .Call('_asapR_mmutil_read_rows_columns', PACKAGE = 'asapR', mtx_file, memory_location, r_row_index, r_column_index, verbose)
}

#' Simulate sparse counting data with a mixture of Poisson parameters
#'
#'
#' @param r_mu_list a list of gene x individual matrices
#' @param Ncell the total number of cells (may not make it if too sparse)
#' @param output a file header string for output files
#' @param dir_alpha a parameter for Dirichlet(alpha * [1, ..., 1])
#' @param gam_alpha a parameter for Gamma(alpha, beta)
#' @param gam_beta a parameter for Gamma(alpha, beta)
#' @param rseed random seed
#'
mmutil_simulate_poisson_mixture <- function(r_mu_list, Ncell, output, dir_alpha = 1.0, gam_alpha = 2.0, gam_beta = 2.0, rseed = 42L) {
    .Call('_asapR_mmutil_simulate_poisson_mixture', PACKAGE = 'asapR', r_mu_list, Ncell, output, dir_alpha, gam_alpha, gam_beta, rseed)
}

#' Simulation Poisson data based on Mu
#'
#' M= num. of features and n= num. of indv
#'
#' @param mu depth-adjusted mean matrix (M x n)
#' @param rho column depth vector (N x 1), N= num. of cells
#' @param output header for ${output}.{mtx.gz,cols.gz,indv.gz}
#' @param r_indv N x 1 individual membership (1-based, [1 .. n])
#' @param rseed random seed
#'
#' @return a list of file names: {output}.{mtx,rows,cols}.gz
#'
mmutil_simulate_poisson <- function(mu, rho, output, r_indv = NULL, rseed = 42L) {
    .Call('_asapR_mmutil_simulate_poisson', PACKAGE = 'asapR', mu, rho, output, r_indv, rseed)
}

